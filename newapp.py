import streamlit as st
import os
from dotenv import load_dotenv
from mistralai import Mistral, UserMessage

# Load environment variables
load_dotenv()

# Set page configuration
st.set_page_config(page_title="ì¹œêµ¬ë´‡", page_icon="ğŸ¤–")

# Mistral í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” 
# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë‚˜ Streamlit secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
try:
    client = Mistral(api_key=os.getenv("MISTRAL_API_KEY") or st.secrets["MISTRAL_API_KEY"])
except Exception as e:
    st.error(f"API í‚¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    client = None

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
DEFAULT_MODEL = "mistral-large-latest"

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì •ì˜
SYSTEM_MESSAGE = '''
ë„ˆì˜ ì´ë¦„ì€ ì¹œêµ¬ë´‡ì´ì•¼. ë„ˆëŠ” í•­ìƒ ë°˜ë§ì„ í•˜ëŠ” ì±—ë´‡ì´ì•¼. 
ë‹¤ë‚˜ê¹Œë‚˜ ìš” ê°™ì€ ë†’ì„ë§ë¡œ ì ˆëŒ€ë¡œ ëë‚´ì§€ ë§ˆ. 
í•­ìƒ ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜. 
ëŒ€ë‹µì˜ ì²« ë§ˆë””ëŠ” í•­ìƒ "ìƒìœ¤ì•„ ë‚´ë§ì„ ë“¤ì–´ë´!"ë¼ê³  ì‹œì‘í•´ì¤˜.
ì˜ì–´ë¡œ ì§ˆë¬¸ì„ ë°›ì•„ë„ ë¬´ì¡°ê±´ í•œê¸€ë¡œ ë‹µë³€í•´ì¤˜. 
í•œê¸€ì´ ì•„ë‹Œ ë‹µë³€ì¼ ë•ŒëŠ” ë‹¤ì‹œ ìƒê°í•´ì„œ ê¼­ í•œê¸€ë¡œ ë§Œë“¤ì–´ì¤˜. 
ëª¨ë“  ë‹µë³€ ëì— ë‹µë³€ì— ë§ëŠ” ì´ëª¨í‹°ì½˜ë„ ì¶”ê°€í•´ì¤˜.
'''

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", 
             "content": SYSTEM_MESSAGE}
        ]
    if "mistral_model" not in st.session_state:
        st.session_state["mistral_model"] = DEFAULT_MODEL

# ë©”ì‹œì§€ í‘œì‹œ í•¨ìˆ˜
def display_messages():
    for message in st.session_state.messages[1:]:  # system message ì œì™¸
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì±„íŒ… ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜
def get_chat_response(messages):
    try:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ í•¨ê»˜ ë©”ì‹œì§€ ì¤€ë¹„
        chat_response = client.chat.stream(
            model=st.session_state["mistral_model"],
            messages=messages
        )
#        print(dir(chat_response))
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        response_content = ""
        for chunk in chat_response:
#            print(chunk)
            if chunk.data:
                response_content += chunk.data.choices[0].delta.content  # ì—¬ê¸° ìˆ˜ì •
#                print(response_content)
#                print(f"Received chunk: {chunk.data.choices[0].delta.content}")
        return response_content
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì£„ì†¡í•´. í˜„ì¬ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ìˆì–´. ë‹¤ì‹œ ì‹œë„í•´ì¤„ë˜? "
# ë©”ì¸ ì•± ë¡œì§
def main():
    # í˜ì´ì§€ ì œëª©
    st.title("ğŸ¤– ì¹œêµ¬ë´‡")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()

    # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
    display_messages()

    # API í´ë¼ì´ì–¸íŠ¸ í™•ì¸
    if not client:
        st.warning("API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ì–´. API í‚¤ë¥¼ í™•ì¸í•´ì¤˜! ğŸš¨")
        return

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ë¬´ìŠ¨ ì–˜ê¸° í•˜ê³  ì‹¶ì–´?"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        user_message = {"role": "user", "content": prompt}
        st.session_state.messages.append(user_message)
        
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                # ì „ì²´ ë©”ì‹œì§€ ì¤€ë¹„ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨)
                response_messages = st.session_state.messages

                # ì‘ë‹µ ìƒì„±
                response = get_chat_response(response_messages)

                # ì‘ë‹µ í‘œì‹œ ë° ì„¸ì…˜ì— ì¶”ê°€
                st.markdown(response)
                
                # AI ë©”ì‹œì§€ ì„¸ì…˜ì— ì¶”ê°€
                ai_message = {"role": "assistant", "content": response}
                st.session_state.messages.append(ai_message)

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    main()